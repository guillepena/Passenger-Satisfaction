---
title: "Airline passengers satisfaction"
author: "Guillermo Pe√±a"
date: "03/01/2021"
output: html_document
---

This dataset contains an airline passenger satisfaction survey. The main questions that comes to mind are:

1. What factors are highly correlated to a satisfied (or dissatisfied) passenger?
2. Can you predict passenger satisfaction?

We are looking into a dataset that has been split in train and test datasets with 22 variables subject to explain the satisfaction variable which takes two values: "satisfied" or "neutral or dissatisfied".


Necessary libraries for the analysis
```{r}
if (!require(broom)) install.packages('broom')
if (!require(tidyverse)) install.packages('tidyverse')
if (!require(caret)) install.packages('caret')
if (!require(MASS)) install.packages('MASS')
if (!require(ROCR)) install.packages('ROCR')
if (!require(readr)) install.packages('readr')
library(broom)
library(tidyverse)
library(caret)
library(MASS)
library(ROCR)
library(readr)
```


```{r}
url_train <- "https://raw.githubusercontent.com/guillepena/Passenger-Satisfaction/master/train.csv"
train_data <- read.csv(url_train,header=TRUE)
url_test <- "https://raw.githubusercontent.com/guillepena/Passenger-Satisfaction/master/test.csv"
test_data <- read.csv(url_test,header=TRUE)
```


The proportion of people for the two satisfaction levels are:

```{r}
table(train_data$satisfaction)
```

We first transform the variables that came from a rating to factor format.

```{r}
train_data$Inflight.wifi.service = as.factor(train_data$Inflight.wifi.service)
train_data$Departure.Arrival.time.convenient = as.factor(train_data$Departure.Arrival.time.convenient)
train_data$Ease.of.Online.booking = as.factor(train_data$Ease.of.Online.booking) 
train_data$Gate.location = as.factor(train_data$Gate.location)
train_data$Food.and.drink = as.factor(train_data$Food.and.drink)
train_data$Online.boarding = as.factor(train_data$Online.boarding)
train_data$Seat.comfort = as.factor(train_data$Seat.comfort)
train_data$Inflight.entertainment = as.factor(train_data$Inflight.entertainment)
train_data$On.board.service = as.factor(train_data$On.board.service)
train_data$Leg.room.service = as.factor(train_data$Leg.room.service)
train_data$Baggage.handling = as.factor(train_data$Baggage.handling)
train_data$Checkin.service = as.factor(train_data$Checkin.service)
train_data$Inflight.service = as.factor(train_data$Inflight.service)
train_data$Cleanliness = as.factor(train_data$Cleanliness)
train_data$satisfaction = as.factor(train_data$satisfaction)
str(train_data)
```

```{r}
test_data$Inflight.wifi.service = as.factor(test_data$Inflight.wifi.service)
test_data$Departure.Arrival.time.convenient = as.factor(test_data$Departure.Arrival.time.convenient)
test_data$Ease.of.Online.booking = as.factor(test_data$Ease.of.Online.booking) 
test_data$Gate.location = as.factor(test_data$Gate.location)
test_data$Food.and.drink = as.factor(test_data$Food.and.drink)
test_data$Online.boarding = as.factor(test_data$Online.boarding)
test_data$Seat.comfort = as.factor(test_data$Seat.comfort)
test_data$Inflight.entertainment = as.factor(test_data$Inflight.entertainment)
test_data$On.board.service = as.factor(test_data$On.board.service)
test_data$Leg.room.service = as.factor(test_data$Leg.room.service)
test_data$Baggage.handling = as.factor(test_data$Baggage.handling)
test_data$Checkin.service = as.factor(test_data$Checkin.service)
test_data$Inflight.service = as.factor(test_data$Inflight.service)
test_data$Cleanliness = as.factor(test_data$Cleanliness)
test_data$satisfaction = as.factor(test_data$satisfaction)
str(test_data)
```

Perform a copy of the datasets.
```{r}
train_data_copy = train_data
test_data_copy = test_data
```

We want to make sure that we have no NAs in the dataset
```{r}
NA_position_train <- which(is.na(train_data_copy$Arrival.Delay.in.Minutes))
train_data_copy$Arrival.Delay.in.Minutes[NA_position_train] = mean(train_data_copy$Arrival.Delay.in.Minutes, na.rm = TRUE)
NA_position_test <- which(is.na(test_data_copy$Arrival.Delay.in.Minutes))
test_data_copy$Arrival.Delay.in.Minutes[NA_position_test] = mean(test_data_copy$Arrival.Delay.in.Minutes, na.rm = TRUE)
```


We try first to perform a logistic regression model on the dataset.
```{r}
est_mod <- glm(satisfaction ~ Gender + Customer.Type + Age + 
                 Type.of.Travel + Class + Flight.Distance + Inflight.wifi.service + 
                 Departure.Arrival.time.convenient + Ease.of.Online.booking + 
                 Gate.location + Food.and.drink + Online.boarding + Seat.comfort +
                 Inflight.entertainment + On.board.service + Leg.room.service +
                 Baggage.handling + Checkin.service + Inflight.service +
                 Cleanliness + Departure.Delay.in.Minutes + Arrival.Delay.in.Minutes , data = train_data_copy, family = "binomial")

summary(est_mod)
```

We can see some variables with low significancy.
To improve the robustness of the model we can rebuild it with the variables that have higher significancy.

```{r}
est_mod_1 <- glm(satisfaction ~ Customer.Type + Age + Type.of.Travel + Class + 
                  Departure.Arrival.time.convenient + Ease.of.Online.booking + 
                  Online.boarding  +
                  Baggage.handling + Checkin.service + Inflight.service +
                  Cleanliness + Departure.Delay.in.Minutes + Arrival.Delay.in.Minutes , data = train_data_copy, family = "binomial")

summary(est_mod_1)
```

The power of the model is already looking much better.

```{r}
predict <- predict(est_mod_1, type = 'response' , newdata=test_data_copy)

summary(predict)
```


ROC curve.
The ROC curve plots sensitivity (TPR) versus 1 - specificity or the false positive rate (FPR).
It gives us an idea of the trade-offs to make when choosing a cutoff for prediction.
In this analysis we are going to benefit accuracy.

```{r}
ROCRpred <- prediction(predict, test_data_copy$satisfaction)
ROCRperf <- performance(ROCRpred, 'tpr','fpr')
plot(ROCRperf, colorize = TRUE, print.cutoffs.at=seq(0,1,by=0.1),text.adj = c(-0.2,1.7))
```


The area under the curve (AUC) of the ROC plot is:
```{r}
AUC <- as.numeric(performance(ROCRpred, "auc")@y.values)
AUC
```

In short, this measure ranging from 0 to 1, shows how well the classification model is performing in general, where the higher the number the better. 

```{r}
cutoff <- seq(0,1,.1)
accuracy <- map_dbl(cutoff, function(x){
    y_hat <- ifelse(as.numeric(predict) > x,"satisfied", "neutral or dissatisfied")
    mean(y_hat == test_data_copy$satisfaction) })

plot(cutoff,accuracy)

max(accuracy)

best_cutoff <- cutoff[which.max(accuracy)]
best_cutoff
```


From the ROC Curve, we found 0.6 is the optimum threshold value for Cut-off.

Confussion Matrix

```{r}
y_hat <- ifelse(as.numeric(predict) > best_cutoff,"satisfied", "neutral or dissatisfied")
cm <- confusionMatrix(data = as.factor(y_hat), reference = test_data_copy$satisfaction)

cm$overall["Accuracy"]

cm$byClass[c("F1","Sensitivity","Specificity","Prevalence")]

```


Decision tree model:

We want to compare the logistic regression model with a decision tree model, looking at what model performs best overall.
```{r}

if (!require(rpart)) install.packages('rpart')
library(rpart)
```

```{r}
tree <- rpart(satisfaction ~ Gender + Customer.Type + Age + 
               Type.of.Travel + Class + Flight.Distance + Inflight.wifi.service + 
               Departure.Arrival.time.convenient + Ease.of.Online.booking + 
               Gate.location + Food.and.drink + Online.boarding + Seat.comfort +
               Inflight.entertainment + On.board.service + Leg.room.service +
               Baggage.handling + Checkin.service + Inflight.service +
               Cleanliness + Departure.Delay.in.Minutes + Arrival.Delay.in.Minutes , 
             data = train_data_copy, method = 'class', minbucket=25)
```

Analyzing the importance of the variables in the tree model using varImp function.
```{r}
varImp(tree)
```

We rebuid the model with only the variables with higher importance in the model.

```{r}
tree1 <- rpart(satisfaction ~  Age + Type.of.Travel + Class + Inflight.wifi.service + 
                Ease.of.Online.booking + Online.boarding + Seat.comfort +
               Inflight.entertainment + On.board.service + Leg.room.service +
               Baggage.handling + Checkin.service + Inflight.service +
               Cleanliness + Arrival.Delay.in.Minutes,
               data = train_data_copy, method = 'class', minbucket=25)

plot(tree1, margin = 0.1)
text(tree1, cex = 0.4)
```

```{r}
predict_cart <- predict(tree1, newdata = test_data_copy, class="tree")
```

```{r}
#Plotting the ROC Curve
pred <- prediction(predict_cart[,2], test_data_copy$satisfaction)
perf <- performance(pred, "tpr", "fpr")
plot(perf, colorize = TRUE, print.cutoffs.at=seq(0,1,by=0.1),text.adj = c(-0.2,1.7))
```


```{r}
########################### Optimization Part
# Define cross-validation experiment
numFolds = trainControl( method = "cv", number = 10 )
cpGrid = expand.grid( .cp = seq(0.01,0.5,0.01))
```

```{r}
train_rpart <- train(satisfaction ~  Age + Type.of.Travel + Class + Inflight.wifi.service + 
        Ease.of.Online.booking + Online.boarding + Seat.comfort +
        Inflight.entertainment + On.board.service + Leg.room.service +
        Baggage.handling + Checkin.service + Inflight.service +
        Cleanliness + Arrival.Delay.in.Minutes, 
      data = train_data_copy, method = "rpart", trControl = numFolds, tuneGrid = cpGrid )

plot(train_rpart)
```


```{r}
y_hat_cart <- predict(train_rpart,test_data_copy)
cm_cart <- confusionMatrix(data = as.factor(y_hat_cart), reference = test_data_copy$satisfaction)

cm_cart$overall["Accuracy"]

cm_cart$byClass[c("F1","Sensitivity","Specificity","Prevalence")]
```

Very often it is useful to have a single number as a summary of performace, for example for optimization purposes when we don't want to work wih many objective functions. One metric that is preferred over overall accuracy is an average of specificity and sensitivity, referred to as balanced accuracy. Because specificity and sensitivity are rates, it is more appropriate to compute the harmonic average. In fact, the F1-score, a widely used one-number summary, is the harmonic average of precision and recall.

Looking at the F1 meassure of the models we can see that the logistic regression performs better.

The F1 meassure for logistic regression is:
```{r}
cm$byClass["F1"]
```
The F1 meassure for the tree model is:
```{r}
cm_cart$byClass["F1"]
```

